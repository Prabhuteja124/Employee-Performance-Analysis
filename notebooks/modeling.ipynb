{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e837db",
   "metadata": {},
   "source": [
    "***\n",
    "# Essential Installation and libraries initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feb689b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd3a687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f373d0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 23:06:11,704 - load_data - INFO - Loading Data from file...\n",
      "2025-07-25 23:06:11,925 - load_data - INFO - Excel Dataset Loaded Successfully!\n",
      "2025-07-25 23:06:11,929 - load_data - INFO -  Dataset Shape: 1200 rows and 28 columns.\n"
     ]
    }
   ],
   "source": [
    "from src.utils.load_data import DataLoader\n",
    "loader=DataLoader()\n",
    "df=loader.load_dataset('INX_Future_Inc_Employee_Performance_CDS_Project2_Data_V1.8.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c43e75b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('EmpNumber',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2487068c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 23:06:12,017 - preprocess - INFO - Initialized Preprocessor with input Dataframe.\n",
      "2025-07-25 23:06:12,023 - preprocess - INFO - Starting Preprocessing Pipeline...\n",
      "2025-07-25 23:06:12,023 - preprocess - INFO - Dropped Columns : ['EmpJobLevel', 'ExperienceYearsAtThisCompany']\n",
      "2025-07-25 23:06:12,023 - utils - INFO - Train-Test Split Initialized ...\n",
      "2025-07-25 23:06:12,031 - utils - INFO - Training set shape: (960, 24), Testing set shape: (240, 24)\n",
      "2025-07-25 23:06:12,034 - utils - INFO - Target distribution (train):\n",
      "{1: 699, 0: 155, 2: 106}\n",
      "2025-07-25 23:06:12,036 - utils - INFO - Target distribution (test):\n",
      "{1: 175, 0: 39, 2: 26}\n",
      "2025-07-25 23:06:12,038 - preprocess - INFO - ColumnTransformer pipeline defined...\n",
      "2025-07-25 23:06:12,048 - preprocess - INFO - Applying ordinal encoding.\n",
      "2025-07-25 23:06:12,048 - preprocess - INFO - Encoded column: Gender\n",
      "2025-07-25 23:06:12,056 - preprocess - INFO - Encoded column: MaritalStatus\n",
      "2025-07-25 23:06:12,056 - preprocess - INFO - Encoded column: BusinessTravelFrequency\n",
      "2025-07-25 23:06:12,056 - preprocess - INFO - Encoded column: OverTime\n",
      "2025-07-25 23:06:12,064 - preprocess - INFO - Encoded column: Attrition\n",
      "2025-07-25 23:06:12,067 - preprocess - INFO - Applying log transformation\n",
      "2025-07-25 23:06:12,081 - preprocess - INFO - Applying ordinal encoding.\n",
      "2025-07-25 23:06:12,101 - preprocess - INFO - Encoded column: Gender\n",
      "2025-07-25 23:06:12,107 - preprocess - INFO - Encoded column: MaritalStatus\n",
      "2025-07-25 23:06:12,111 - preprocess - INFO - Encoded column: BusinessTravelFrequency\n",
      "2025-07-25 23:06:12,115 - preprocess - INFO - Encoded column: OverTime\n",
      "2025-07-25 23:06:12,117 - preprocess - INFO - Encoded column: Attrition\n",
      "2025-07-25 23:06:12,117 - preprocess - INFO - Applying log transformation\n",
      "2025-07-25 23:06:12,124 - preprocess - INFO - Fitted pipeline on X_train and transformed both train and test data.\n",
      "2025-07-25 23:06:12,129 - preprocess - INFO - Getting feature names from ColumnTransformer pipeline...\n",
      "2025-07-25 23:06:12,133 - preprocess - INFO - Saved the preprocessing pipeline to 'Preprocessor.pkl':f:\\Machine_Learning\\Ml_Projects\\INX_Employee_Performance\\models.\n"
     ]
    }
   ],
   "source": [
    "from src.Data_Processing.preprocess import Preprocessor\n",
    "preprocessor=Preprocessor(df)\n",
    "X_train,X_test,y_train,y_test=preprocessor.preprocess_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83642432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Machine_Learning\\\\Ml_Projects\\\\INX_Employee_Performance\\\\models'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.path.dirname(os.getcwd()),'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d7fe40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 23:06:12,393 - train_model - INFO - Model directory initialized at f:\\Machine_Learning\\Ml_Projects\\INX_Employee_Performance\\models\n",
      "2025-07-25 23:06:12,393 - train_model - INFO - Model directory initialized at f:\\Machine_Learning\\Ml_Projects\\INX_Employee_Performance\\models\n",
      "2025-07-25 23:06:12,393 - train_model - INFO - Training started for all models...\n",
      "2025-07-25 23:06:12,400 - train_model - INFO - Training LogisticRegression\n",
      "2025-07-25 23:06:14,761 - train_model - INFO - Training RidgeClassifier\n",
      "2025-07-25 23:06:14,771 - train_model - INFO - Training SVM\n",
      "2025-07-25 23:06:15,000 - train_model - INFO - Training DecisionTree\n",
      "2025-07-25 23:06:15,013 - train_model - INFO - Training RandomForest\n",
      "2025-07-25 23:06:15,256 - train_model - INFO - Training GradientBoosting\n",
      "2025-07-25 23:06:16,273 - train_model - INFO - Training naive_bayes\n",
      "2025-07-25 23:06:16,282 - train_model - INFO - Training AdaBoost\n",
      "2025-07-25 23:06:16,454 - train_model - INFO - Training XGBoost\n",
      "2025-07-25 23:06:16,773 - train_model - INFO - Training LightGBM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 362\n",
      "[LightGBM] [Info] Number of data points in the train set: 960, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 23:06:17,137 - train_model - INFO - Starting Model Evaluation....\n",
      "2025-07-25 23:06:17,139 - train_model - INFO - Evaluating Model : LogisticRegression\n",
      "2025-07-25 23:06:17,149 - train_model - INFO - LogisticRegression - Train Accuracy: 0.785 | Train F1: 0.799\n",
      "2025-07-25 23:06:17,151 - train_model - INFO - LogisticRegression - Test Accuracy: 0.758 | Test F1: 0.772\n",
      "2025-07-25 23:06:17,157 - train_model - INFO - LogisticRegression - ROC AUC: 0.873\n",
      "2025-07-25 23:06:17,159 - train_model - INFO - Confusion Matrix for LogisticRegression:\n",
      "[[ 29   7   3]\n",
      " [ 24 134  17]\n",
      " [  2   5  19]]\n",
      "2025-07-25 23:06:17,161 - train_model - INFO - Evaluating Model : RidgeClassifier\n",
      "2025-07-25 23:06:17,172 - train_model - INFO - RidgeClassifier - Train Accuracy: 0.740 | Train F1: 0.757\n",
      "2025-07-25 23:06:17,172 - train_model - INFO - RidgeClassifier - Test Accuracy: 0.696 | Test F1: 0.719\n",
      "2025-07-25 23:06:17,174 - train_model - INFO - RidgeClassifier does not support predict_proba; ROC AUC skipped.\n",
      "2025-07-25 23:06:17,177 - train_model - INFO - Confusion Matrix for RidgeClassifier:\n",
      "[[ 30   5   4]\n",
      " [ 32 117  26]\n",
      " [  2   4  20]]\n",
      "2025-07-25 23:06:17,177 - train_model - INFO - Evaluating Model : SVM\n",
      "2025-07-25 23:06:17,273 - train_model - INFO - SVM - Train Accuracy: 0.892 | Train F1: 0.896\n",
      "2025-07-25 23:06:17,273 - train_model - INFO - SVM - Test Accuracy: 0.804 | Test F1: 0.813\n",
      "2025-07-25 23:06:17,303 - train_model - INFO - SVM - ROC AUC: 0.922\n",
      "2025-07-25 23:06:17,305 - train_model - INFO - Confusion Matrix for SVM:\n",
      "[[ 32   5   2]\n",
      " [ 21 142  12]\n",
      " [  1   6  19]]\n",
      "2025-07-25 23:06:17,305 - train_model - INFO - Evaluating Model : DecisionTree\n",
      "2025-07-25 23:06:17,310 - train_model - INFO - DecisionTree - Train Accuracy: 1.000 | Train F1: 1.000\n",
      "2025-07-25 23:06:17,321 - train_model - INFO - DecisionTree - Test Accuracy: 0.921 | Test F1: 0.921\n",
      "2025-07-25 23:06:17,328 - train_model - INFO - DecisionTree - ROC AUC: 0.906\n",
      "2025-07-25 23:06:17,328 - train_model - INFO - Confusion Matrix for DecisionTree:\n",
      "[[ 31   8   0]\n",
      " [  8 165   2]\n",
      " [  0   1  25]]\n",
      "2025-07-25 23:06:17,328 - train_model - INFO - Evaluating Model : RandomForest\n",
      "2025-07-25 23:06:17,516 - train_model - INFO - RandomForest - Train Accuracy: 1.000 | Train F1: 1.000\n",
      "2025-07-25 23:06:17,516 - train_model - INFO - RandomForest - Test Accuracy: 0.925 | Test F1: 0.922\n",
      "2025-07-25 23:06:17,595 - train_model - INFO - RandomForest - ROC AUC: 0.947\n",
      "2025-07-25 23:06:17,595 - train_model - INFO - Confusion Matrix for RandomForest:\n",
      "[[ 31   8   0]\n",
      " [  3 172   0]\n",
      " [  0   7  19]]\n",
      "2025-07-25 23:06:17,595 - train_model - INFO - Evaluating Model : GradientBoosting\n",
      "2025-07-25 23:06:17,621 - train_model - INFO - GradientBoosting - Train Accuracy: 0.995 | Train F1: 0.995\n",
      "2025-07-25 23:06:17,621 - train_model - INFO - GradientBoosting - Test Accuracy: 0.929 | Test F1: 0.928\n",
      "2025-07-25 23:06:17,631 - train_model - INFO - GradientBoosting - ROC AUC: 0.978\n",
      "2025-07-25 23:06:17,631 - train_model - INFO - Confusion Matrix for GradientBoosting:\n",
      "[[ 33   5   1]\n",
      " [  4 170   1]\n",
      " [  0   6  20]]\n",
      "2025-07-25 23:06:17,631 - train_model - INFO - Evaluating Model : naive_bayes\n",
      "2025-07-25 23:06:17,647 - train_model - INFO - naive_bayes - Train Accuracy: 0.246 | Train F1: 0.135\n",
      "2025-07-25 23:06:17,647 - train_model - INFO - naive_bayes - Test Accuracy: 0.200 | Test F1: 0.114\n",
      "2025-07-25 23:06:17,656 - train_model - INFO - naive_bayes - ROC AUC: 0.760\n",
      "2025-07-25 23:06:17,656 - train_model - INFO - Confusion Matrix for naive_bayes:\n",
      "[[32  0  7]\n",
      " [85  4 86]\n",
      " [14  0 12]]\n",
      "2025-07-25 23:06:17,659 - train_model - INFO - Evaluating Model : AdaBoost\n",
      "2025-07-25 23:06:17,691 - train_model - INFO - AdaBoost - Train Accuracy: 0.863 | Train F1: 0.855\n",
      "2025-07-25 23:06:17,691 - train_model - INFO - AdaBoost - Test Accuracy: 0.858 | Test F1: 0.851\n",
      "2025-07-25 23:06:17,700 - train_model - INFO - AdaBoost - ROC AUC: 0.915\n",
      "2025-07-25 23:06:17,712 - train_model - INFO - Confusion Matrix for AdaBoost:\n",
      "[[ 23  15   1]\n",
      " [  5 167   3]\n",
      " [  1   9  16]]\n",
      "2025-07-25 23:06:17,712 - train_model - INFO - Evaluating Model : XGBoost\n",
      "2025-07-25 23:06:17,740 - train_model - INFO - XGBoost - Train Accuracy: 1.000 | Train F1: 1.000\n",
      "2025-07-25 23:06:17,740 - train_model - INFO - XGBoost - Test Accuracy: 0.921 | Test F1: 0.918\n",
      "2025-07-25 23:06:17,750 - train_model - INFO - XGBoost - ROC AUC: 0.969\n",
      "2025-07-25 23:06:17,752 - train_model - INFO - Confusion Matrix for XGBoost:\n",
      "[[ 30   8   1]\n",
      " [  3 171   1]\n",
      " [  0   6  20]]\n",
      "2025-07-25 23:06:17,754 - train_model - INFO - Evaluating Model : LightGBM\n",
      "2025-07-25 23:06:17,770 - train_model - INFO - LightGBM - Train Accuracy: 1.000 | Train F1: 1.000\n",
      "2025-07-25 23:06:17,772 - train_model - INFO - LightGBM - Test Accuracy: 0.942 | Test F1: 0.941\n",
      "2025-07-25 23:06:17,780 - train_model - INFO - LightGBM - ROC AUC: 0.979\n",
      "2025-07-25 23:06:17,782 - train_model - INFO - Confusion Matrix for LightGBM:\n",
      "[[ 33   5   1]\n",
      " [  4 170   1]\n",
      " [  0   3  23]]\n",
      "2025-07-25 23:06:17,784 - train_model - INFO - Evaluation completed for all models.\n",
      "2025-07-25 23:06:17,784 - evaluate_model - INFO - Saving the best Model...\n",
      "2025-07-25 23:06:17,786 - evaluate_model - INFO - Getting the best model based on F1 Score.\n",
      "2025-07-25 23:06:17,786 - evaluate_model - INFO - Best Model :LightGBM with F1-Score : 0.941\n",
      "2025-07-25 23:06:17,790 - evaluate_model - INFO - Best Model is LGBMClassifier(class_weight='balanced', n_jobs=-1) | F1-Score = 0.941\n",
      "2025-07-25 23:06:17,827 - evaluate_model - INFO - Model Saved Succesfully at : f:\\Machine_Learning\\Ml_Projects\\INX_Employee_Performance\\models\\LightGBM_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "from src.models.train_model import ModelTrainer\n",
    "from src.models.evaluate_model import  save_best_model\n",
    "\n",
    "trainer=ModelTrainer()\n",
    "train_models=trainer.train_models(X_train,y_train)\n",
    "evaluate_models=trainer.evaluate_models(X_train,y_train,X_test,y_test)\n",
    "best_model,result=save_best_model(evaluate_models,train_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c164d20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "train_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "train_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ROC",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "80a61020-2cad-46d5-a721-e5c676b077da",
       "rows": [
        [
         "0",
         "LogisticRegression",
         "0.7854166666666667",
         "0.7985135374493653",
         "0.7583333333333333",
         "0.7723739532931222",
         "0.8725071220103651"
        ],
        [
         "1",
         "RidgeClassifier",
         "0.7395833333333334",
         "0.7565659834591874",
         "0.6958333333333333",
         "0.7185382031506854",
         null
        ],
        [
         "2",
         "SVM",
         "0.8916666666666667",
         "0.8961669875794215",
         "0.8041666666666667",
         "0.8129535943049426",
         "0.9221606382179686"
        ],
        [
         "3",
         "DecisionTree",
         "1.0",
         "1.0",
         "0.9208333333333333",
         "0.9208378385684166",
         "0.9061958360605314"
        ],
        [
         "4",
         "RandomForest",
         "1.0",
         "1.0",
         "0.925",
         "0.922404940700937",
         "0.9471132155243434"
        ],
        [
         "5",
         "GradientBoosting",
         "0.9947916666666666",
         "0.9948101371819519",
         "0.9291666666666667",
         "0.9277913299165517",
         "0.9782472149794997"
        ],
        [
         "6",
         "naive_bayes",
         "0.24583333333333332",
         "0.13523351761736552",
         "0.2",
         "0.11361225320867398",
         "0.7600083708583848"
        ],
        [
         "7",
         "AdaBoost",
         "0.8625",
         "0.8554049334259656",
         "0.8583333333333333",
         "0.8507031792284506",
         "0.9145442427510184"
        ],
        [
         "8",
         "XGBoost",
         "1.0",
         "1.0",
         "0.9208333333333333",
         "0.9184027777777778",
         "0.9688381957931406"
        ],
        [
         "9",
         "LightGBM",
         "1.0",
         "1.0",
         "0.9416666666666667",
         "0.94114434265829",
         "0.9789228238748744"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.798514</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.772374</td>\n",
       "      <td>0.872507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.756566</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.718538</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.896167</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.812954</td>\n",
       "      <td>0.922161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920833</td>\n",
       "      <td>0.920838</td>\n",
       "      <td>0.906196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.922405</td>\n",
       "      <td>0.947113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.994792</td>\n",
       "      <td>0.994810</td>\n",
       "      <td>0.929167</td>\n",
       "      <td>0.927791</td>\n",
       "      <td>0.978247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.245833</td>\n",
       "      <td>0.135234</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.113612</td>\n",
       "      <td>0.760008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.855405</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.850703</td>\n",
       "      <td>0.914544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920833</td>\n",
       "      <td>0.918403</td>\n",
       "      <td>0.968838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.941144</td>\n",
       "      <td>0.978923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  train_accuracy  train_f1  test_accuracy   test_f1  \\\n",
       "0  LogisticRegression        0.785417  0.798514       0.758333  0.772374   \n",
       "1     RidgeClassifier        0.739583  0.756566       0.695833  0.718538   \n",
       "2                 SVM        0.891667  0.896167       0.804167  0.812954   \n",
       "3        DecisionTree        1.000000  1.000000       0.920833  0.920838   \n",
       "4        RandomForest        1.000000  1.000000       0.925000  0.922405   \n",
       "5    GradientBoosting        0.994792  0.994810       0.929167  0.927791   \n",
       "6         naive_bayes        0.245833  0.135234       0.200000  0.113612   \n",
       "7            AdaBoost        0.862500  0.855405       0.858333  0.850703   \n",
       "8             XGBoost        1.000000  1.000000       0.920833  0.918403   \n",
       "9            LightGBM        1.000000  1.000000       0.941667  0.941144   \n",
       "\n",
       "        ROC  \n",
       "0  0.872507  \n",
       "1       NaN  \n",
       "2  0.922161  \n",
       "3  0.906196  \n",
       "4  0.947113  \n",
       "5  0.978247  \n",
       "6  0.760008  \n",
       "7  0.914544  \n",
       "8  0.968838  \n",
       "9  0.978923  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pd.DataFrame(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d438ecf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 23:06:17,842 - predict_model - INFO - Loading Model and Preprocessor ...\n",
      "2025-07-25 23:06:17,858 - predict_model - INFO - Model and Preprocessor are loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from src.models.predict_model import InferencePipeline\n",
    "pipeline=InferencePipeline('models\\LightGBM_best_model.pkl','models\\Preprocessor.pkl')\n",
    "pipeline.load_artifacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdcc9e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 23:06:17,871 - predict_model - INFO - Started inference...\n",
      "2025-07-25 23:06:17,880 - preprocess - INFO - Applying ordinal encoding.\n",
      "2025-07-25 23:06:17,884 - preprocess - INFO - Encoded column: Gender\n",
      "2025-07-25 23:06:17,889 - preprocess - INFO - Encoded column: MaritalStatus\n",
      "2025-07-25 23:06:17,893 - preprocess - INFO - Encoded column: BusinessTravelFrequency\n",
      "2025-07-25 23:06:17,897 - preprocess - INFO - Encoded column: OverTime\n",
      "2025-07-25 23:06:17,900 - preprocess - INFO - Encoded column: Attrition\n",
      "2025-07-25 23:06:17,902 - preprocess - INFO - Applying log transformation\n",
      "2025-07-25 23:06:17,911 - predict_model - INFO - Inference completed succesfully.\n"
     ]
    }
   ],
   "source": [
    "prediction=pipeline.predict({'Age': 32,\n",
    " 'Gender': 'Male',\n",
    " 'EducationBackground': 'Marketing',\n",
    " 'MaritalStatus': 'Single',\n",
    " 'EmpDepartment': 'Sales',\n",
    " 'EmpJobRole': 'Sales Executive',\n",
    " 'BusinessTravelFrequency': 'Travel_Rarely',\n",
    " 'DistanceFromHome': 10,\n",
    " 'EmpEducationLevel': 3,\n",
    " 'EmpEnvironmentSatisfaction': 4,\n",
    " 'EmpHourlyRate': 55,\n",
    " 'EmpJobInvolvement': 3,\n",
    " 'EmpJobLevel': 2,\n",
    " 'EmpJobSatisfaction': 4,\n",
    " 'NumCompaniesWorked': 1,\n",
    " 'OverTime': 'No',\n",
    " 'EmpLastSalaryHikePercent': 12,\n",
    " 'EmpRelationshipSatisfaction': 4,\n",
    " 'TotalWorkExperienceInYears': 10,\n",
    " 'TrainingTimesLastYear': 2,\n",
    " 'EmpWorkLifeBalance': 2,\n",
    " 'ExperienceYearsAtThisCompany': 10,\n",
    " 'ExperienceYearsInCurrentRole': 7,\n",
    " 'YearsSinceLastPromotion': 0,\n",
    " 'YearsWithCurrManager': 8,\n",
    " 'Attrition': 'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f33a066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2911b1bb-3aab-43ce-9887-dc4ebf267d0d",
       "rows": [
        [
         "0",
         "3"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 1
       }
      },
      "text/plain": [
       "0    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d986e4b",
   "metadata": {},
   "source": [
    "# INX Employee Performance Prediction - Project Summary\n",
    "\n",
    "## 1. Data Loading\n",
    "\n",
    "- Data loaded successfully from Excel file.\n",
    "- Rows: 1200  \n",
    "- Columns: 28  \n",
    "\n",
    "## 2. Data Preprocessing\n",
    "\n",
    "- Dropped Irrelevant Columns:  \n",
    "  - EmpJobLevel  \n",
    "  - ExperienceYearsAtThisCompany\n",
    "\n",
    "- Train-Test Split:\n",
    "  - Training Set Shape: (960, 24)  \n",
    "  - Testing Set Shape: (240, 24)\n",
    "\n",
    "- Target Distribution (Train):  \n",
    "  {1: 699, 0: 155, 2: 106}\n",
    "\n",
    "- Target Distribution (Test):  \n",
    "  {1: 175, 0: 39, 2: 26}\n",
    "\n",
    "- Ordinal Encoded Categorical Features:\n",
    "  - Gender\n",
    "  - MaritalStatus\n",
    "  - BusinessTravelFrequency\n",
    "  - OverTime\n",
    "  - Attrition\n",
    "\n",
    "- Applied log transformation to selected numerical columns.\n",
    "\n",
    "- ColumnTransformer pipeline created and fitted on train data.  \n",
    "- Preprocessor saved as: Preprocessor.pkl\n",
    "\n",
    "## 3. Model Training\n",
    "\n",
    "- Model directory created: models/\n",
    "\n",
    "- Trained Models:\n",
    "  - Logistic Regression\n",
    "  - Ridge Classifier\n",
    "  - Support Vector Machine (SVM)\n",
    "  - Decision Tree\n",
    "  - Random Forest\n",
    "  - Gradient Boosting\n",
    "  - Naive Bayes\n",
    "  - AdaBoost\n",
    "  - XGBoost\n",
    "  - LightGBM\n",
    "\n",
    "## 4. Model Evaluation\n",
    "\n",
    "- Metrics computed for each model:\n",
    "  - Accuracy\n",
    "  - F1 Score\n",
    "  - ROC-AUC Score (where applicable)\n",
    "  - Confusion Matrix\n",
    "\n",
    "### Best Performing Models:\n",
    "\n",
    "#### LightGBM:\n",
    "- Test Accuracy: 94.2%\n",
    "- F1 Score: 0.941\n",
    "- ROC-AUC Score: 0.979\n",
    "- Confusion Matrix:\n",
    "  [[33, 5, 1],  \n",
    "   [4, 170, 1],  \n",
    "   [0, 3, 23]]\n",
    "\n",
    "#### XGBoost:\n",
    "- Test Accuracy: 92.1%\n",
    "- F1 Score: 0.918\n",
    "- ROC-AUC Score: 0.969\n",
    "\n",
    "#### Gradient Boosting:\n",
    "- Test Accuracy: 92.9%\n",
    "- F1 Score: 0.928\n",
    "- ROC-AUC Score: 0.978\n",
    "\n",
    "## 5. Best Model Selection\n",
    "\n",
    "- Best Model based on highest F1 Score: LightGBM\n",
    "- Saved Model: models/LightGBM_best_model.pkl\n",
    "\n",
    "## 6. Prediction\n",
    "\n",
    "- Loaded saved model and preprocessor\n",
    "- Performed inference successfully on test data\n",
    "\n",
    "## Final Remarks\n",
    "\n",
    "- All steps from preprocessing to prediction were executed successfully.\n",
    "- Project pipeline is complete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e1b4a",
   "metadata": {},
   "source": [
    "##  Conclusion\n",
    "\n",
    "- This project assessed a range of classification algorithms to predict employee performance levels using a structured and preprocessed dataset. Key preprocessing steps—including label encoding, SMOTE for class balancing, and PCA for dimensionality reduction—were uniformly applied to ensure fair and efficient model comparisons.\n",
    "\n",
    "- Among the evaluated models, **LightGBM** and **Gradient Boosting** demonstrated the best performance with **94% accuracy and 0.94 f1 score**, leveraging their ability to handle complex feature interactions and imbalanced data. **XGBoost**, **Random Forest**, and **Decision Tree** also performed strongly with test accuracies around **92%**, showcasing the reliability of tree-based ensemble methods.\n",
    "\n",
    "- While models like **Logistic Regression** and **Ridge Classifier** offered simplicity and interpretability, they underperformed compared to ensemble and kernel-based approaches, achieving around **75–76% accuracy**. **SVM** provided a good balance of complexity and performance, reaching **80% accuracy and 0.81 f1 score**.\n",
    "\n",
    "- The **Naive Bayes classifier** struggled significantly due to its strong independence assumptions, resulting in the lowest performance.\n",
    "\n",
    "- Overall, the results suggest that for high-dimensional, imbalanced datasets with mixed data types, **boosting and ensemble methods (LightGBM, Gradient Boosting, Random Forest)** are highly effective, especially when combined with robust preprocessing pipelines.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
